{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import heapq\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arrange = pd.read_csv(\"reviews_sentiment.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Promedio de palabras por estrellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 12.216216216216216, 2: 41.916666666666664, 3: 8.08974358974359, 4: 16.366666666666667, 5: 4.2727272727272725}\n"
     ]
    }
   ],
   "source": [
    "def meanWordsByStars(df):\n",
    "    wordsByStars = {}\n",
    "    for i in range(1,6):\n",
    "        dfAux = df[df['Star Rating'] == i]\n",
    "        wordsByStars[i] = dfAux[\"wordcount\"].mean()\n",
    "    return wordsByStars\n",
    "\n",
    "print(meanWordsByStars(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Procesamiento del dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_11116\\2993762873.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed['titleSentiment'] = df_processed['titleSentiment'].apply(string_to_float)\n",
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_11116\\2993762873.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed['textSentiment'] = df_processed['textSentiment'].apply(string_to_float)\n"
     ]
    }
   ],
   "source": [
    "df_processed = df.dropna()\n",
    "\n",
    "def string_to_float(string):\n",
    "    if string == 'positive':\n",
    "        return 1\n",
    "    elif string == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return string  # Return the original value if it's neither 'positive' nor 'negative'\n",
    "\n",
    "df_processed['titleSentiment'] = df_processed['titleSentiment'].apply(string_to_float)\n",
    "df_processed['textSentiment'] = df_processed['textSentiment'].apply(string_to_float)\n",
    "\n",
    "#muestra el dataframe modificado\n",
    "df_processed.to_csv('modified_dataframe.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conjunto de entrenamiento y variables predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 47\n"
     ]
    }
   ],
   "source": [
    "# choose the columns to be used as features for training the model\n",
    "X = df_processed[['wordcount', 'titleSentiment', 'sentimentValue']]\n",
    "Y = df_processed['Star Rating']\n",
    "# train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Estandarización/Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de los datos\n",
    "#scaler_standard = StandardScaler()\n",
    "#X_train = scaler_standard.fit_transform(X_train)  # Ajustar y transformar los datos de entrenamiento\n",
    "#X_test = scaler_standard.transform(X_test)  # Transformar los datos de prueba\n",
    "\n",
    "# Normalización de los datos\n",
    "#scaler_minmax = MinMaxScaler()\n",
    "#X_train = scaler_minmax.fit_transform(X_train)  # Ajustar y transformar los datos de entrenamiento\n",
    "#X_test = scaler_minmax.transform(X_test)  # Transformar los datos de prueba \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Implementación del modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  2  0  0]\n",
      " [ 0  6  0  0  0]\n",
      " [ 1  1  8  2  0]\n",
      " [ 0  1  2  2  0]\n",
      " [ 0  0  2  0 16]]\n",
      "Accuracy:  0.7659574468085106\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cálculo de distancias euclidianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la distancia euclidiana\n",
    "def distancia_euclidiana(punto1, punto2):\n",
    "    return np.sqrt(np.sum((punto1 - punto2) ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Función KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función KNN para clasificar un nuevo punto\n",
    "def knn_clasificar(X_train, Y_train, punto_nuevo, k):\n",
    "    distancias = []\n",
    "    \n",
    "    # Calcular distancias entre el nuevo punto y todos los puntos en el conjunto de entrenamiento\n",
    "    for i in range(len(X_train)):\n",
    "        distancia = distancia_euclidiana(np.array(punto_nuevo), np.array(X_train[i]))\n",
    "        distancias.append((distancia, Y_train[i]))\n",
    "    \n",
    "    # Ordenar las distancias\n",
    "    distancias.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Seleccionar los K vecinos más cercanos\n",
    "    vecinos_mas_cercanos = [distancia[1] for distancia in distancias[:k]]\n",
    "    \n",
    "    # Contar la clase más común entre los K vecinos\n",
    "    clase_mas_comun = max(set(vecinos_mas_cercanos), key=vecinos_mas_cercanos.count)\n",
    "    \n",
    "    return clase_mas_comun\n",
    "\n",
    "# Convert to numpy arrays if they are pandas DataFrames\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train = X_train.to_numpy()\n",
    "if isinstance(Y_train, pd.Series):\n",
    "    Y_train = Y_train.to_numpy()\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    X_test = X_test.to_numpy()\n",
    "if isinstance(Y_test, pd.Series):\n",
    "    Y_test = Y_test.to_numpy()\n",
    "\n",
    "# Clasificar los puntos del conjunto de prueba\n",
    "predicciones = []\n",
    "k = 3  # Puedes ajustar este valor según lo que prefieras\n",
    "\n",
    "for punto in X_test:\n",
    "    try:\n",
    "        #print(\"Punto a clasificar:\", punto)\n",
    "        prediccion = knn_clasificar(X_train, Y_train, punto, k)\n",
    "        predicciones.append(prediccion)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} - Check the data format and indexing.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b. Evaluación del modelo KNN con pesos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función KNN para clasificar un nuevo punto con pesos\n",
    "def knn_clasificar(X_train, Y_train, punto_nuevo, k):\n",
    "    distancias = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        distancia = distancia_euclidiana(np.array(punto_nuevo), np.array(X_train[i]))\n",
    "        distancias.append((distancia, Y_train[i]))\n",
    "    \n",
    "    # Ordenar las distancias\n",
    "    distancias.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Calcular los pesos y la suma ponderada de las clases\n",
    "    pesos_clases = {}\n",
    "    \n",
    "    for distancia, clase in distancias[:k]:\n",
    "        if distancia == 0:  # Para evitar división por cero\n",
    "            peso = float('inf')  # O asignar un peso muy alto\n",
    "        else:\n",
    "            peso = 1 / (distancia ** 2)\n",
    "        \n",
    "        if clase in pesos_clases:\n",
    "            pesos_clases[clase] += peso\n",
    "        else:\n",
    "            pesos_clases[clase] = peso\n",
    "    \n",
    "    # Obtener la clase con el mayor peso\n",
    "    clase_mas_comun = max(pesos_clases, key=pesos_clases.get)\n",
    "    \n",
    "    return clase_mas_comun\n",
    "\n",
    "\n",
    "# Convert to numpy arrays if they are pandas DataFrames\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train = X_train.to_numpy()\n",
    "if isinstance(Y_train, pd.Series):\n",
    "    Y_train = Y_train.to_numpy()\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    X_test = X_test.to_numpy()\n",
    "if isinstance(Y_test, pd.Series):\n",
    "    Y_test = Y_test.to_numpy()\n",
    "\n",
    "\n",
    "# Clasificar los puntos del conjunto de prueba\n",
    "predicciones = []\n",
    "k = 3  # Puedes ajustar este valor según lo que prefieras\n",
    "for punto in X_test:\n",
    "    prediccion = knn_clasificar(X_train, Y_train, punto, k)\n",
    "    predicciones.append(prediccion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7872340425531915\n",
      "Precision:  0.7956731628821742\n",
      "Recall:  0.7872340425531915\n",
      "F1 Score:  0.7893595765936191\n",
      "Confusion Matrix:\n",
      " [[ 4  0  2  0  0]\n",
      " [ 0  6  0  0  0]\n",
      " [ 1  0  9  2  0]\n",
      " [ 0  0  0  3  2]\n",
      " [ 0  0  3  0 15]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, predicciones))\n",
    "print(\"Precision: \", precision_score(Y_test, predicciones, average='weighted'))\n",
    "print(\"Recall: \", recall_score(Y_test, predicciones, average='weighted'))\n",
    "print(\"F1 Score: \", f1_score(Y_test, predicciones, average='weighted'))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, predicciones))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
